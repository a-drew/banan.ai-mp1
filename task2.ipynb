{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/a-drew/banan.ai-mp1/blob/main/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Imports and Globals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn import *\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from time import time\n",
    "\n",
    "# controls max iterations of the MLP Classifier. Set higher for better results. Convergence warnings were silenced\n",
    "max_iter = 4000\n",
    "t = time()\n",
    "name = 'test79'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Load the df in Python (you can use pandas.read csv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               int64\n",
      "Sex              object\n",
      "BP             category\n",
      "Cholesterol    category\n",
      "Na_to_K         float64\n",
      "Drug           category\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Age Sex      BP Cholesterol  Na_to_K   Drug\n0    39   F     LOW      NORMAL   22.697  drugY\n1    36   F    HIGH        HIGH   11.198  drugA\n2    29   F    HIGH        HIGH   29.450  drugY\n3    72   M     LOW        HIGH   16.310  drugY\n4    50   F  NORMAL      NORMAL   12.295  drugX\n5    49   F  NORMAL      NORMAL    9.381  drugX\n6    22   M  NORMAL        HIGH   11.953  drugX\n7    47   F     LOW        HIGH   11.767  drugC\n8    58   F     LOW        HIGH   38.247  drugY\n9    46   M  NORMAL      NORMAL    7.285  drugX\n10   62   M     LOW      NORMAL   27.183  drugY\n11   28   F     LOW        HIGH   19.796  drugY\n12   36   F  NORMAL        HIGH   16.753  drugY\n13   23   M  NORMAL      NORMAL   14.020  drugX\n14   68   M    HIGH        HIGH   11.009  drugB\n15   15   M  NORMAL        HIGH    9.084  drugX\n16   19   F    HIGH        HIGH   13.313  drugA\n17   72   M     LOW        HIGH    6.769  drugC\n18   47   M     LOW      NORMAL   33.542  drugY\n19   47   M     LOW      NORMAL   30.568  drugY\n20   59   F     LOW        HIGH   10.444  drugC\n21   23   M    HIGH        HIGH    8.011  drugA\n22   52   M     LOW      NORMAL   32.922  drugY\n23   47   F     LOW        HIGH   10.067  drugC\n24   62   M  NORMAL        HIGH   16.594  drugY\n25   22   M    HIGH      NORMAL   28.294  drugY\n26   39   M  NORMAL        HIGH   15.969  drugY\n27   19   F    HIGH      NORMAL   25.969  drugY\n28   18   F  NORMAL      NORMAL    8.750  drugX\n29   43   M     LOW        HIGH   15.376  drugY\n30   56   M  NORMAL        HIGH    8.966  drugX\n31   28   F  NORMAL        HIGH    7.798  drugX\n32   57   F  NORMAL        HIGH   14.216  drugX\n33   18   F    HIGH      NORMAL   24.276  drugY\n34   56   F     LOW        HIGH   11.567  drugC\n35   36   F    HIGH      NORMAL   15.490  drugY\n36   72   F     LOW      NORMAL   14.642  drugX\n37   34   M    HIGH        HIGH   18.703  drugY\n38   70   F  NORMAL        HIGH   20.489  drugY\n39   40   M    HIGH        HIGH   27.826  drugY\n40   49   F  NORMAL        HIGH   16.275  drugY\n41   56   F    HIGH        HIGH   25.395  drugY\n42   69   M     LOW      NORMAL   11.455  drugX\n43   68   F    HIGH      NORMAL   10.189  drugB\n44   45   M     LOW      NORMAL   10.017  drugX\n45   65   M    HIGH      NORMAL   34.997  drugY\n46   28   F    HIGH      NORMAL   18.809  drugY\n47   74   F     LOW        HIGH   20.942  drugY\n48   74   M    HIGH      NORMAL   15.436  drugY\n49   60   M    HIGH        HIGH   13.934  drugB",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Drug</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>22.697</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>11.198</td>\n      <td>drugA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>29.450</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>16.310</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>NORMAL</td>\n      <td>12.295</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>NORMAL</td>\n      <td>9.381</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>11.953</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>11.767</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>58</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>38.247</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>NORMAL</td>\n      <td>7.285</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>62</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>27.183</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>19.796</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>36</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>16.753</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>NORMAL</td>\n      <td>14.020</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>68</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>11.009</td>\n      <td>drugB</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>9.084</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>19</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>13.313</td>\n      <td>drugA</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>72</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>6.769</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>33.542</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>30.568</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>59</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>10.444</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>8.011</td>\n      <td>drugA</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>52</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>32.922</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>47</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>10.067</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>62</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>16.594</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>22</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>28.294</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>39</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>15.969</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>19</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>25.969</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>18</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>NORMAL</td>\n      <td>8.750</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>43</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>15.376</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>56</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>8.966</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>28</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>7.798</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>57</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>14.216</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>18</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>24.276</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>56</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>11.567</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>15.490</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>72</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>14.642</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>34</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>18.703</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>70</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>20.489</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>27.826</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>16.275</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>56</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>25.395</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>69</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>11.455</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>68</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>10.189</td>\n      <td>drugB</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>10.017</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>65</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>34.997</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>28</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>18.809</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>74</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>20.942</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>74</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>NORMAL</td>\n      <td>15.436</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>60</td>\n      <td>M</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>13.934</td>\n      <td>drugB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'data/{name}.csv', dtype={'BP': 'category', 'Cholesterol': 'category', 'Drug': 'category'})\n",
    "print(df.dtypes)\n",
    "x = df.loc[:, ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']]\n",
    "y = df['Drug']\n",
    "classes = np.unique(y)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Class Distribution\n",
    "Plot the distribution of the instances in each class and store the graphic in a file called drug-distribution.pdf.\n",
    "You can use matplotlib.pyplot. This pre-analysis will allow you to determine if the classes are balanced,\n",
    "and which metric is more appropriate to use to evaluate the performance of your classifier."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drugA': 3, 'drugB': 3, 'drugC': 5, 'drugX': 13, 'drugY': 26}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = {drug: np.count_nonzero(y == drug) for drug in classes}\n",
    "print(counts)\n",
    "\n",
    "plt.pie(counts.values(), labels=classes, autopct='%1.1f%%')\n",
    "plt.title('Class Distribution')\n",
    "\n",
    "plt.savefig('output/drug-distribution.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Convert Features to Numerical Form\n",
    "Convert all ordinal and nominal features in numerical format. Make sure that your converted format\n",
    "respects the ordering of ordinal features, and does not introduce any ordering for nominal features.\n",
    "You may want to take a look at pandas.get dummies and pandas.Categorical to do this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     4\n",
      "1     0\n",
      "2     4\n",
      "3     4\n",
      "4     3\n",
      "5     3\n",
      "6     3\n",
      "7     2\n",
      "8     4\n",
      "9     3\n",
      "10    4\n",
      "11    4\n",
      "12    4\n",
      "13    3\n",
      "14    1\n",
      "15    3\n",
      "16    0\n",
      "17    2\n",
      "18    4\n",
      "19    4\n",
      "20    2\n",
      "21    0\n",
      "22    4\n",
      "23    2\n",
      "24    4\n",
      "25    4\n",
      "26    4\n",
      "27    4\n",
      "28    3\n",
      "29    4\n",
      "30    3\n",
      "31    3\n",
      "32    3\n",
      "33    4\n",
      "34    2\n",
      "35    4\n",
      "36    3\n",
      "37    4\n",
      "38    4\n",
      "39    4\n",
      "40    4\n",
      "41    4\n",
      "42    3\n",
      "43    1\n",
      "44    3\n",
      "45    4\n",
      "46    4\n",
      "47    4\n",
      "48    4\n",
      "49    1\n",
      "dtype: int8\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Age  BP  Cholesterol  Na_to_K  Sex_F  Sex_M\n0    39   1            1   22.697      1      0\n1    36   0            0   11.198      1      0\n2    29   0            0   29.450      1      0\n3    72   1            0   16.310      0      1\n4    50   2            1   12.295      1      0\n5    49   2            1    9.381      1      0\n6    22   2            0   11.953      0      1\n7    47   1            0   11.767      1      0\n8    58   1            0   38.247      1      0\n9    46   2            1    7.285      0      1\n10   62   1            1   27.183      0      1\n11   28   1            0   19.796      1      0\n12   36   2            0   16.753      1      0\n13   23   2            1   14.020      0      1\n14   68   0            0   11.009      0      1\n15   15   2            0    9.084      0      1\n16   19   0            0   13.313      1      0\n17   72   1            0    6.769      0      1\n18   47   1            1   33.542      0      1\n19   47   1            1   30.568      0      1\n20   59   1            0   10.444      1      0\n21   23   0            0    8.011      0      1\n22   52   1            1   32.922      0      1\n23   47   1            0   10.067      1      0\n24   62   2            0   16.594      0      1\n25   22   0            1   28.294      0      1\n26   39   2            0   15.969      0      1\n27   19   0            1   25.969      1      0\n28   18   2            1    8.750      1      0\n29   43   1            0   15.376      0      1\n30   56   2            0    8.966      0      1\n31   28   2            0    7.798      1      0\n32   57   2            0   14.216      1      0\n33   18   0            1   24.276      1      0\n34   56   1            0   11.567      1      0\n35   36   0            1   15.490      1      0\n36   72   1            1   14.642      1      0\n37   34   0            0   18.703      0      1\n38   70   2            0   20.489      1      0\n39   40   0            0   27.826      0      1\n40   49   2            0   16.275      1      0\n41   56   0            0   25.395      1      0\n42   69   1            1   11.455      0      1\n43   68   0            1   10.189      1      0\n44   45   1            1   10.017      0      1\n45   65   0            1   34.997      0      1\n46   28   0            1   18.809      1      0\n47   74   1            0   20.942      1      0\n48   74   0            1   15.436      0      1\n49   60   0            0   13.934      0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Sex_F</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.697</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11.198</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29.450</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16.310</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2</td>\n      <td>1</td>\n      <td>12.295</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>49</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9.381</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22</td>\n      <td>2</td>\n      <td>0</td>\n      <td>11.953</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.767</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.247</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7.285</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>27.183</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19.796</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>36</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.753</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23</td>\n      <td>2</td>\n      <td>1</td>\n      <td>14.020</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11.009</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9.084</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.313</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6.769</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>47</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.542</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>47</td>\n      <td>1</td>\n      <td>1</td>\n      <td>30.568</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>59</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.444</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.011</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>52</td>\n      <td>1</td>\n      <td>1</td>\n      <td>32.922</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>47</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.067</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>62</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.594</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>28.294</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>39</td>\n      <td>2</td>\n      <td>0</td>\n      <td>15.969</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>19</td>\n      <td>0</td>\n      <td>1</td>\n      <td>25.969</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>18</td>\n      <td>2</td>\n      <td>1</td>\n      <td>8.750</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>43</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15.376</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>56</td>\n      <td>2</td>\n      <td>0</td>\n      <td>8.966</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>28</td>\n      <td>2</td>\n      <td>0</td>\n      <td>7.798</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>57</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.216</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>18</td>\n      <td>0</td>\n      <td>1</td>\n      <td>24.276</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>56</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.567</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15.490</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>72</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.642</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18.703</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>70</td>\n      <td>2</td>\n      <td>0</td>\n      <td>20.489</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.826</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.275</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.395</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>69</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11.455</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>68</td>\n      <td>0</td>\n      <td>1</td>\n      <td>10.189</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10.017</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>65</td>\n      <td>0</td>\n      <td>1</td>\n      <td>34.997</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>28</td>\n      <td>0</td>\n      <td>1</td>\n      <td>18.809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>74</td>\n      <td>1</td>\n      <td>0</td>\n      <td>20.942</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>74</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15.436</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.934</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_numerical = pd.get_dummies(x, columns=['Sex'])\n",
    "x_numerical['BP'] = x_numerical['BP'].cat.codes\n",
    "x_numerical['Cholesterol'] = x_numerical['Cholesterol'].cat.codes\n",
    "y_numerical = y.cat.codes\n",
    "\n",
    "print(y_numerical)\n",
    "x_numerical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Split the data into Training & Testing Sets\n",
    "Split the dataset using train_test_split using the default parameter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     3\n",
      "39    4\n",
      "33    4\n",
      "9     3\n",
      "10    4\n",
      "2     4\n",
      "3     4\n",
      "43    1\n",
      "16    0\n",
      "19    4\n",
      "25    4\n",
      "47    4\n",
      "23    2\n",
      "22    4\n",
      "28    3\n",
      "31    3\n",
      "34    2\n",
      "18    4\n",
      "7     2\n",
      "40    4\n",
      "42    3\n",
      "44    3\n",
      "30    3\n",
      "37    4\n",
      "8     4\n",
      "26    4\n",
      "29    4\n",
      "1     0\n",
      "38    4\n",
      "11    4\n",
      "15    3\n",
      "14    1\n",
      "48    4\n",
      "13    3\n",
      "27    4\n",
      "20    2\n",
      "36    3\n",
      "dtype: int8\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Age  BP  Cholesterol  Na_to_K  Sex_F  Sex_M\n4    50   2            1   12.295      1      0\n39   40   0            0   27.826      0      1\n33   18   0            1   24.276      1      0\n9    46   2            1    7.285      0      1\n10   62   1            1   27.183      0      1\n2    29   0            0   29.450      1      0\n3    72   1            0   16.310      0      1\n43   68   0            1   10.189      1      0\n16   19   0            0   13.313      1      0\n19   47   1            1   30.568      0      1\n25   22   0            1   28.294      0      1\n47   74   1            0   20.942      1      0\n23   47   1            0   10.067      1      0\n22   52   1            1   32.922      0      1\n28   18   2            1    8.750      1      0\n31   28   2            0    7.798      1      0\n34   56   1            0   11.567      1      0\n18   47   1            1   33.542      0      1\n7    47   1            0   11.767      1      0\n40   49   2            0   16.275      1      0\n42   69   1            1   11.455      0      1\n44   45   1            1   10.017      0      1\n30   56   2            0    8.966      0      1\n37   34   0            0   18.703      0      1\n8    58   1            0   38.247      1      0\n26   39   2            0   15.969      0      1\n29   43   1            0   15.376      0      1\n1    36   0            0   11.198      1      0\n38   70   2            0   20.489      1      0\n11   28   1            0   19.796      1      0\n15   15   2            0    9.084      0      1\n14   68   0            0   11.009      0      1\n48   74   0            1   15.436      0      1\n13   23   2            1   14.020      0      1\n27   19   0            1   25.969      1      0\n20   59   1            0   10.444      1      0\n36   72   1            1   14.642      1      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Sex_F</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2</td>\n      <td>1</td>\n      <td>12.295</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.826</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>18</td>\n      <td>0</td>\n      <td>1</td>\n      <td>24.276</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7.285</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>27.183</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29.450</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16.310</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>68</td>\n      <td>0</td>\n      <td>1</td>\n      <td>10.189</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.313</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>47</td>\n      <td>1</td>\n      <td>1</td>\n      <td>30.568</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>28.294</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>74</td>\n      <td>1</td>\n      <td>0</td>\n      <td>20.942</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>47</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.067</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>52</td>\n      <td>1</td>\n      <td>1</td>\n      <td>32.922</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>18</td>\n      <td>2</td>\n      <td>1</td>\n      <td>8.750</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>28</td>\n      <td>2</td>\n      <td>0</td>\n      <td>7.798</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>56</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.567</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>47</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.542</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.767</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.275</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>69</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11.455</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10.017</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>56</td>\n      <td>2</td>\n      <td>0</td>\n      <td>8.966</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18.703</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.247</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>39</td>\n      <td>2</td>\n      <td>0</td>\n      <td>15.969</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>43</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15.376</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11.198</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>70</td>\n      <td>2</td>\n      <td>0</td>\n      <td>20.489</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19.796</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9.084</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11.009</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>74</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15.436</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23</td>\n      <td>2</td>\n      <td>1</td>\n      <td>14.020</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>19</td>\n      <td>0</td>\n      <td>1</td>\n      <td>25.969</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>59</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.444</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>72</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.642</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = skl.model_selection.train_test_split(x_numerical, y_numerical)\n",
    "print(y_train)\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    4\n",
      "41    4\n",
      "32    3\n",
      "21    0\n",
      "6     3\n",
      "45    4\n",
      "35    4\n",
      "0     4\n",
      "49    1\n",
      "46    4\n",
      "17    2\n",
      "5     3\n",
      "24    4\n",
      "dtype: int8\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Age  BP  Cholesterol  Na_to_K  Sex_F  Sex_M\n12   36   2            0   16.753      1      0\n41   56   0            0   25.395      1      0\n32   57   2            0   14.216      1      0\n21   23   0            0    8.011      0      1\n6    22   2            0   11.953      0      1\n45   65   0            1   34.997      0      1\n35   36   0            1   15.490      1      0\n0    39   1            1   22.697      1      0\n49   60   0            0   13.934      0      1\n46   28   0            1   18.809      1      0\n17   72   1            0    6.769      0      1\n5    49   2            1    9.381      1      0\n24   62   2            0   16.594      0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Sex_F</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>36</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.753</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.395</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>57</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.216</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.011</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22</td>\n      <td>2</td>\n      <td>0</td>\n      <td>11.953</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>65</td>\n      <td>0</td>\n      <td>1</td>\n      <td>34.997</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15.490</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.697</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.934</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>28</td>\n      <td>0</td>\n      <td>1</td>\n      <td>18.809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6.769</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>49</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9.381</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>62</td>\n      <td>2</td>\n      <td>0</td>\n      <td>16.594</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test)\n",
    "x_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Run Different Classifiers:\n",
    "    (a) NB: a Gaussian Naive Bayes Classifier (naive bayes.GaussianNB) with the default parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Gaussian NB training...\n",
      "done in 0.004s\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "print(\"\\nPerforming Gaussian NB training...\")\n",
    "t0 = time()\n",
    "gnb = skl.naive_bayes.GaussianNB()\n",
    "models.append(gnb)\n",
    "gnb.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (b) Base-DT: a Decision Tree (tree.DecisionTreeClassifier) with the default parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Base Decision Tree training...\n",
      "done in 0.005s\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Base Decision Tree training...\")\n",
    "t0 = time()\n",
    "bdt = skl.tree.DecisionTreeClassifier()\n",
    "models.append(bdt)\n",
    "bdt.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (c) Top-DT: a better performing Decision Tree found using (GridSearchCV). The gridsearch will allow\n",
    "    you to find the best combination of hyper-parameters, as determined by the evaluation function that\n",
    "    you have determined in step (3) above. The hyper-parameters that you will experiment with are:\n",
    "        - criterion: gini or entropy\n",
    "        - max depth : 2 different values of your choice\n",
    "        - min samples split: 3 different values of your choice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Top-DT training w/ grid search...\n",
      "parameters: {'criterion': ['gini', 'entropy'], 'max_depth': [4, 5], 'min_samples_split': [2, 5, 10]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.243s\n",
      "Best score: 0.861\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Top-DT training w/ grid search...\")\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "print(\"parameters:\", parameters)\n",
    "t0 = time()\n",
    "tdt = skl.model_selection.GridSearchCV(skl.tree.DecisionTreeClassifier(), parameters)\n",
    "models.append(tdt)\n",
    "tdt.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best score: %0.3f\" % tdt.best_score_)\n",
    "print(\"Best parameters:\", tdt.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (d) PER: a Perceptron (linear model.Perceptron), with default parameter values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Perceptron training...\n",
      "done in 0.006s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Perceptron training...\")\n",
    "t0 = time()\n",
    "per = skl.linear_model.Perceptron()\n",
    "models.append(per)\n",
    "per.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (e) Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier) with 1 hidden layer of\n",
    "    100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values\n",
    "    for the rest of the parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Base Multi-Layered Perceptron training...\n",
      "done in 0.872s\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Base Multi-Layered Perceptron training...\")\n",
    "t0 = time()\n",
    "bmlp = skl.neural_network.MLPClassifier(hidden_layer_sizes=100, activation='logistic', solver='sgd', max_iter=max_iter)\n",
    "models.append(bmlp)\n",
    "#with ignore_warnings(category=skl.exceptions.ConvergenceWarning):\n",
    "bmlp.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (f) Top-MLP: a better performing Multi-Layered Perceptron found using grid search. For this, you need\n",
    "    to experiment with the following parameter values:\n",
    "        - activation function: sigmoid, tanh, relu and identity\n",
    "        - 2 network architectures of your choice: for eg 2 hidden layers with 30 + 50 nodes, 3 hidden layers with 10 + 10 + 10\n",
    "        - solver: Adam and stochastic gradient descent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Top-MLP training w/ grid search...\n",
      "parameters: {'hidden_layer_sizes': [(10, 20), (15, 15, 15)], 'activation': ['logistic', 'tanh', 'relu', 'identity'], 'solver': ['sgd', 'adam']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 35.655s\n",
      "Best score: 0.864\n",
      "Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 20), 'solver': 'adam'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Top-MLP training w/ grid search...\")\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10, 20), (15, 15, 15)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "}\n",
    "print(\"parameters:\", parameters)\n",
    "t0 = time()\n",
    "tmlp = skl.model_selection.GridSearchCV(skl.neural_network.MLPClassifier(max_iter=max_iter), parameters)\n",
    "models.append(tmlp)\n",
    "#with ignore_warnings(category=skl.exceptions.ConvergenceWarning):\n",
    "tmlp.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best score: %0.3f\" % tmlp.best_score_)\n",
    "print(\"Best parameters:\", tmlp.best_params_)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 7. Report Best Hyperparameters and Metrics for each Classifier\n",
    "For each of the 6 classifier above, append the following information in a file called drugs-performance.txt:\n",
    "\n",
    "    (a) a clear separator (a sequence of hyphens or stars) and a string clearly describing the model (e.g. the\n",
    "        model name + hyper-parameter values that you changed). In the case of Top-DT and Top-MLP,\n",
    "        display the best hyperparameters found by the gridsearch.\n",
    "    (b) the confusion matrix\n",
    "    (c) the precision, recall, and F1-measure for each class\n",
    "    (d) the accuracy, macro-average F1 and weighted-average F1 of the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 7:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'output/drug-performance-{name}.txt'):\n",
    "    os.remove(f'output/drug-performance-{name}.txt')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.FileHandler(f'output/drug-performance-{name}.txt', 'w'))\n",
    "logger.info(\"Task 7:\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GaussianNB\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 3 0]\n",
      " [0 0 0 0 7]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.31      0.40      0.35        13\n",
      "weighted avg       0.59      0.77      0.67        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "76.92307692307693%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "34.64285714285714%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "66.89560439560441%\n",
      "================================================================================\n",
      "================================================================================\n",
      "DecisionTreeClassifier\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 3 0]\n",
      " [0 0 0 0 7]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "100.0%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "100.0%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "100.0%\n",
      "================================================================================\n",
      "================================================================================\n",
      "Top DecisionTreeClassifier\n",
      "Best parameters: \n",
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 2 1 0]\n",
      " [0 0 0 0 7]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.70      0.67      0.68        13\n",
      "weighted avg       0.81      0.77      0.78        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "76.92307692307693%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "68.0%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "78.46153846153847%\n",
      "================================================================================\n",
      "================================================================================\n",
      "Perceptron\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 3]\n",
      " [0 0 0 0 7]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.54      1.00      0.70         7\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.11      0.20      0.14        13\n",
      "weighted avg       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "53.84615384615385%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "14.000000000000002%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "37.6923076923077%\n",
      "================================================================================\n",
      "================================================================================\n",
      "MLPClassifier\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 2 1]\n",
      " [0 0 0 0 7]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.26      0.33      0.29        13\n",
      "weighted avg       0.53      0.69      0.60        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "69.23076923076923%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "28.92857142857143%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "60.30219780219781%\n",
      "================================================================================\n",
      "================================================================================\n",
      "Top MLPClassifier\n",
      "Best parameters: \n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (10, 20), 'solver': 'adam'}\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 2 0]\n",
      " [1 0 0 0 6]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.28      0.30      0.29        13\n",
      "weighted avg       0.56      0.62      0.58        13\n",
      "\n",
      "\n",
      "(d) accuracy_score: \n",
      "61.53846153846154%\n",
      "\n",
      "(d) f1_score (macro avg): \n",
      "29.333333333333332%\n",
      "\n",
      "(d) f1_score (weighted avg): \n",
      "58.46153846153845%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def performance_report(model):\n",
    "    logger.info('================================================================================')\n",
    "    if isinstance(model, skl.model_selection.GridSearchCV):\n",
    "        logger.info(\"Top \" + type(model.estimator).__name__)\n",
    "        #logger.info(\"Best score: %0.3f\" % model.best_score_)\n",
    "        logger.info(\"Best parameters: \")\n",
    "        logger.info(model.best_params_)\n",
    "    else:\n",
    "        logger.info(type(model).__name__)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    logger.info('\\n(b) confusion_matrix:')\n",
    "    logger.info(skl.metrics.confusion_matrix(y_test, y_pred))\n",
    "    logger.info(\"\\n(c/d) classification_report: \")\n",
    "    logger.info(skl.metrics.classification_report(y_test, y_pred))\n",
    "    logger.info(\"\\n(d) accuracy_score: \")\n",
    "    logger.info(str(100 * skl.metrics.accuracy_score(y_test, y_pred)) + '%')\n",
    "    logger.info(\"\\n(d) f1_score (macro avg): \")\n",
    "    logger.info(str(100 * skl.metrics.f1_score(y_test, y_pred, average='macro')) + '%')\n",
    "    logger.info(\"\\n(d) f1_score (weighted avg): \")\n",
    "    logger.info(str(100 * skl.metrics.f1_score(y_test, y_pred, average='weighted')) + '%')\n",
    "    logger.info('================================================================================')\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    performance_report(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Calculate avg and std Metrics\n",
    "Redo steps 6, 10 times for each model and append the average accuracy, average macro-average F1, average\n",
    "weighted-average F1 as well as the standard deviation for the accuracy, the standard deviation of the macro-average F1,\n",
    "and the standard deviation of the weighted-average F1 at the end of the file drugs-performance.txt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 8:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\nTask 8:\\n\")\n",
    "\n",
    "\n",
    "def train_predict_collect_metrics(model):\n",
    "    #with ignore_warnings(category=skl.exceptions.ConvergenceWarning):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = skl.metrics.accuracy_score(y_test, y_pred)\n",
    "    maf1 = skl.metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    waf1 = skl.metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    return acc, maf1, waf1\n",
    "\n",
    "\n",
    "def general_metrics_report(metrics, desc=None):\n",
    "    logger.info('================================================================================')\n",
    "    if desc is not None:\n",
    "        logger.info(desc)\n",
    "    average = [sum(x) / len(x) for x in zip(*metrics)]\n",
    "    logger.info(\"Average Accuracy: \" + str(100 * average[0]) + \"%\")\n",
    "    logger.info(\"Average macro-average F1: \" + str(100 * average[1]) + \"%\")\n",
    "    logger.info(\"Average weighted-average F1: \" + str(100 * average[2]) + \"%\")\n",
    "    std = [np.std(s) for s in zip(*metrics)]\n",
    "    logger.info(\"Accuracy Standard Deviation: \" + str(std[0]))\n",
    "    logger.info(\"Macro-Average F1 Standard Deviation: \" + str(std[1]))\n",
    "    logger.info(\"Weighted-Average F1 Standard Deviation: \" + str(std[2]))\n",
    "    logger.info('================================================================================')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (a) NB: a Gaussian Naive Bayes Classifier (naive bayes.GaussianNB) with the default parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Metrics for Gaussian NB...\n",
      "run #1\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #2\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Metrics for 10 runs of Gaussian Naive Bayes: \n",
      "Average Accuracy: 76.92307692307693%\n",
      "Average macro-average F1: 34.642857142857146%\n",
      "Average weighted-average F1: 66.8956043956044%\n",
      "Accuracy Standard Deviation: 0.0\n",
      "Macro-Average F1 Standard Deviation: 0.0\n",
      "Weighted-Average F1 Standard Deviation: 0.0\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run #3\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #4\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #5\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #6\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #7\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #8\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #9\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #10\n",
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "done in 0.069s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating Metrics for Gaussian NB...\")\n",
    "t0 = time()\n",
    "gnb_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    gnb = skl.naive_bayes.GaussianNB()\n",
    "    gnb_metrics.append(train_predict_collect_metrics(gnb))\n",
    "    print(gnb_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "general_metrics_report(gnb_metrics, desc=\"Metrics for 10 runs of Gaussian Naive Bayes: \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (b) Base-DT: a Decision Tree (tree.DecisionTreeClassifier) with the default parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Metrics for 10 runs of Base Decision Tree: \n",
      "Average Accuracy: 81.53846153846155%\n",
      "Average macro-average F1: 63.19999999999999%\n",
      "Average weighted-average F1: 82.15384615384616%\n",
      "Accuracy Standard Deviation: 0.15073783032511862\n",
      "Macro-Average F1 Standard Deviation: 0.27988569095257443\n",
      "Weighted-Average F1 Standard Deviation: 0.14418922478596902\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Metrics for Base Decision Tree...\n",
      "run #1\n",
      "(0.6153846153846154, 0.27999999999999997, 0.6307692307692307)\n",
      "run #2\n",
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #3\n",
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #4\n",
      "(1.0, 1.0, 1.0)\n",
      "run #5\n",
      "(0.7692307692307693, 0.6799999999999999, 0.7846153846153846)\n",
      "run #6\n",
      "(0.6153846153846154, 0.27999999999999997, 0.6307692307692307)\n",
      "run #7\n",
      "(0.6153846153846154, 0.27999999999999997, 0.6307692307692307)\n",
      "run #8\n",
      "(1.0, 1.0, 1.0)\n",
      "run #9\n",
      "(1.0, 1.0, 1.0)\n",
      "run #10\n",
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "done in 0.066s\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Metrics for Base Decision Tree...\")\n",
    "t0 = time()\n",
    "bdt_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    bdt = skl.tree.DecisionTreeClassifier()\n",
    "    bdt_metrics.append(train_predict_collect_metrics(bdt))\n",
    "    print(bdt_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "general_metrics_report(bdt_metrics, desc=\"Metrics for 10 runs of Base Decision Tree: \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (c) Top-DT: a better performing Decision Tree found using (GridSearchCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Metrics for Top-DT w/ grid search...\n",
      "run #1\n",
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6153846153846154, 0.27999999999999997, 0.6307692307692307)\n",
      "run #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "run #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "run #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6153846153846154, 0.27999999999999997, 0.6307692307692307)\n",
      "run #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "run #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8461538461538461, 0.6, 0.8461538461538461)\n",
      "run #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "================================================================================\n",
      "Metrics for 10 runs of Top Decision Tree: \n",
      "Average Accuracy: 86.15384615384613%\n",
      "Average macro-average F1: 69.6%\n",
      "Average weighted-average F1: 86.46153846153844%\n",
      "Accuracy Standard Deviation: 0.1410023290755643\n",
      "Macro-Average F1 Standard Deviation: 0.274342851191716\n",
      "Weighted-Average F1 Standard Deviation: 0.13566404729260678\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "done in 2.589s\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Metrics for Top-DT w/ grid search...\")\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "t0 = time()\n",
    "tdt_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    tdt = skl.model_selection.GridSearchCV(skl.tree.DecisionTreeClassifier(), parameters)\n",
    "    tdt_metrics.append(train_predict_collect_metrics(tdt))\n",
    "    print(tdt_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "general_metrics_report(tdt_metrics, desc=\"Metrics for 10 runs of Top Decision Tree: \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (d) PER: a Perceptron (linear model.Perceptron), with default parameter values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Metrics for 10 runs of Perceptron: \n",
      "Average Accuracy: 53.84615384615385%\n",
      "Average macro-average F1: 14.000000000000004%\n",
      "Average weighted-average F1: 37.6923076923077%\n",
      "Accuracy Standard Deviation: 0.0\n",
      "Macro-Average F1 Standard Deviation: 2.7755575615628914e-17\n",
      "Weighted-Average F1 Standard Deviation: 0.0\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Metrics for Perceptron...\n",
      "run #1\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #2\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #3\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #4\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #5\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #6\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #7\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #8\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #9\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "run #10\n",
      "(0.5384615384615384, 0.14, 0.37692307692307697)\n",
      "done in 0.089s\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Metrics for Perceptron...\")\n",
    "t0 = time()\n",
    "per_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    per = skl.linear_model.Perceptron()\n",
    "    per_metrics.append(train_predict_collect_metrics(per))\n",
    "    print(per_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "general_metrics_report(per_metrics, desc=\"Metrics for 10 runs of Perceptron: \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (e) Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Metrics for Base Multi-Layered Perceptron...\n",
      "run #1\n",
      "(0.6923076923076923, 0.30833333333333335, 0.625)\n",
      "run #2\n",
      "(0.6923076923076923, 0.2892857142857143, 0.6030219780219781)\n",
      "run #3\n",
      "(0.7692307692307693, 0.3366666666666666, 0.6756410256410257)\n",
      "run #4\n",
      "(0.7692307692307693, 0.3580952380952381, 0.7003663003663003)\n",
      "run #5\n",
      "(0.6923076923076923, 0.2892857142857143, 0.6030219780219781)\n",
      "run #6\n",
      "(0.6923076923076923, 0.30833333333333335, 0.625)\n",
      "run #7\n",
      "(0.6923076923076923, 0.2892857142857143, 0.6030219780219781)\n",
      "run #8\n",
      "(0.6923076923076923, 0.30833333333333335, 0.625)\n",
      "run #9\n",
      "(0.7692307692307693, 0.3580952380952381, 0.7003663003663003)\n",
      "run #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Metrics for 10 runs of Base Multi-Layered Perceptron: \n",
      "Average Accuracy: 72.3076923076923%\n",
      "Average macro-average F1: 31.823809523809526%\n",
      "Average weighted-average F1: 64.36080586080585%\n",
      "Accuracy Standard Deviation: 0.03768445758127969\n",
      "Macro-Average F1 Standard Deviation: 0.025817517651530206\n",
      "Weighted-Average F1 Standard Deviation: 0.038046928018365206\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.3366666666666666, 0.6756410256410257)\n",
      "done in 11.252s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Metrics for Base Multi-Layered Perceptron...\")\n",
    "t0 = time()\n",
    "bmlp_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    bmlp = skl.neural_network.MLPClassifier(hidden_layer_sizes=100, activation='logistic', solver='sgd', max_iter=max_iter)\n",
    "    bmlp_metrics.append(train_predict_collect_metrics(bmlp))\n",
    "    print(bmlp_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "general_metrics_report(bmlp_metrics, desc=\"Metrics for 10 runs of Base Multi-Layered Perceptron: \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    (f) Top-MLP: a better performing Multi-Layered Perceptron found using grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Metrics for Top Multi-Layered Perceptron...\n",
      "run #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.375, 0.7019230769230769)\n",
      "run #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.5466666666666666, 0.7641025641025642)\n",
      "run #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8461538461538461, 0.5580952380952381, 0.7772893772893773)\n",
      "run #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5384615384615384, 0.20784313725490194, 0.4570135746606334)\n",
      "run #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6153846153846154, 0.32, 0.6153846153846154)\n",
      "run #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.3464285714285714, 0.668956043956044)\n",
      "run #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6923076923076923, 0.3350000000000001, 0.6557692307692309)\n",
      "run #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6923076923076923, 0.30833333333333335, 0.625)\n",
      "run #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/OneDrive - Concordia University - Canada/Conco/21-F/COMP 472/Assignments/COMP472-MP1/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "================================================================================\n",
      "Metrics for 10 runs of Top Multi-Layered Perceptron: \n",
      "Average Accuracy: 73.07692307692307%\n",
      "Average macro-average F1: 39.01890756302521%\n",
      "Average weighted-average F1: 67.11683904330962%\n",
      "Accuracy Standard Deviation: 0.0926276506060946\n",
      "Macro-Average F1 Standard Deviation: 0.11526214077232193\n",
      "Weighted-Average F1 Standard Deviation: 0.09135562221561838\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8461538461538461, 0.5580952380952381, 0.7772893772893773)\n",
      "done in 357.955s\n",
      "\n",
      "\n",
      "\n",
      "Total runtime: 409.389s\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Metrics for Top Multi-Layered Perceptron...\")\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10, 20), (15, 15, 15)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'max_iter': [max_iter],\n",
    "}\n",
    "t0 = time()\n",
    "tmlp_metrics = []\n",
    "for i in range(10):\n",
    "    print('run #' + str(i + 1))\n",
    "    tmlp = skl.model_selection.GridSearchCV(skl.neural_network.MLPClassifier(), parameters)\n",
    "    tmlp_metrics.append(train_predict_collect_metrics(tmlp))\n",
    "    print(tmlp_metrics[-1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "general_metrics_report(tmlp_metrics, desc=\"Metrics for 10 runs of Top Multi-Layered Perceptron: \")\n",
    "\n",
    "print(\"\\n\\nTotal runtime: %0.3fs\" % (time() - t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Analysis\n",
    "Does the same model give you the same performance every time? Explain in a plain text file called drugs-discussion.txt.\n",
    "1 or 2 paragraph discussion is expected."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOM4FWTEFHATi4Q0tnMefGC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}