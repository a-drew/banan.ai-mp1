{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/a-drew/banan.ai-mp1/blob/main/task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaS65pR1SaEY"
   },
   "source": [
    "1. Starter Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HKADUtcgGtiI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEDVj7E3SoRw"
   },
   "source": [
    "2. Pre-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "[510, 386, 417, 511, 401]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = sorted([file for file in os.listdir('data/BBC') if file != 'README.TXT'])\n",
    "print(categories)\n",
    "counts = [len([name for name in os.listdir('data/BBC/' + category)]) for category in categories]\n",
    "print(counts)\n",
    "\n",
    "plt.pie(counts, labels=categories, autopct='%1.1f%%')\n",
    "plt.title('Class Distribution (by file count)')\n",
    "\n",
    "plt.savefig('output/BBC-distribution.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "[0 4 2 3 2]\n",
      "['data/BBC\\\\business\\\\385.txt' 'data/BBC\\\\tech\\\\160.txt'\n",
      " 'data/BBC\\\\politics\\\\090.txt' 'data/BBC\\\\sport\\\\074.txt'\n",
      " 'data/BBC\\\\politics\\\\399.txt']\n",
      "['Tate & Lyle boss bags top award\\r\\n\\r\\nTate & Lyle\\'s chief executive has been named European Businessman of the Year by a leading business magazine.\\r\\n\\r\\nIain Ferguson was awarded the title by US publication Forbes for returning one of the UK\\'s \"venerable\" manufacturers to the country\\'s top 100 companies. The sugar group had been absent from the FTSE 100 for seven years until Mr Ferguson helped it return to growth. Tate\\'s shares have leapt 55% this year, boosted by firming sugar prices and sales of its artificial sweeteners.\\r\\n\\r\\n\"After years of a sagging stock price and a seven-year hiatus from the FTSE 100, one of Britain\\'s venerable manufacturers has returned to the vaunted index,\" Forbes said. Mr Ferguson took the helm at the company in 2003, after spending most of his career at consumer goods giant Unilever. Tate & Lyle, which was an original member of the historic FT-30 index in 1935, operates more than 41 factories and 20 more additional production facilities in 28 countries. Previous winners of the Forbes award include Royal Bank of Scotland chief executive Fred Goodwin and former Vodafone boss Chris Gent.\\r\\n', \"Halo 2 sells five million copies\\r\\n\\r\\nMicrosoft is celebrating bumper sales of its Xbox sci-fi shooter, Halo 2.\\r\\n\\r\\nThe game has sold more than five million copies worldwide since it went on sale in mid-November, the company said. Halo 2 has proved popular online, with gamers notching up a record 28 million hours playing the game on Xbox Live. According to Microsoft, nine out of 10 Xbox Live members have played the game for an average of 91 minutes per session.\\r\\n\\r\\nThe sequel to the best-selling Need for Speed: Underground has inched ahead of the competition to take the top slot in the official UK games charts. The racing game moved up one spot to first place, nudging GTA: San Andreas down to second place. Halo 2 dropped one place to five, while Half-Life 2 fell to number nine. Last week's new releases, GoldenEye: Rogue Agent and Killzone, both failed to make it into the top 10, debuting at number 11 and 12 respectively.\\r\\n\\r\\nRecord numbers of Warcraft fans are settling in the games online world. On the opening day of the World of Warcraft massive multi-player online game more than 200,000 players signed up to play. On the evening of the first day more than 100,000 players were in the world, forcing Blizzard to add another 34 servers to cope with the influx. The online game turns the stand alone Warcraft games into a persistent world that players can inhabit not just visit\\r\\n\\r\\nEurope's gamers could be waiting until January to hear when they can get their mitts on Nintendo's handheld device, Nintendo DS, says gamesindustry.biz. David Yarnton, Nintendo UK general manager, told a press conference to look out for details in the New Year. Its US launch was on Sunday and it goes on sale in Japan on 2 December. Nintendo has a 95% share of the handheld gaming market and said it expected to sell around five million of the DS by March 2005.\\r\\n\", 'MSPs hear renewed climate warning\\r\\n\\r\\nClimate change could be completely out of control within several decades, the Scottish Environment Protection Agency is warning a committee of MSPs.\\r\\n\\r\\nExperts are giving evidence on the subject to the Scottish Parliament\\'s environment committee. Officials believe nuclear energy and wind farms may be better options than trying to tackle global warming. Solutions suggested by conservationists include reducing internal UK air travel and boosting electric trains. The evidence is part of the committee\\'s inquiry into the impact of climate change in Scotland. Sepa is attempting to curb global warming gases, as pollution from transport emissions increases.\\r\\n\\r\\nEcologists are warning MSPs that Scotland may have to accept \"significant intrusion\" from wind farms. It is likely also that nuclear power will be needed for possibly several decades. Sepa predict that the two methods will remain as energy sources until climate change is under control. Experts studying the seas off Scotland\\'s west coast have already forecast more devastating weather of the type which caused havoc across the country last month.\\r\\n\\r\\nThey predicted that damaging storms will become more frequent. Researchers from the University of the Highlands and Islands and Southampton have been looking at wave heights in the Atlantic over the last nine years. The project was conducted jointly by the Environmental Research Institute in Thurso, which is part of the University of the Highlands and Islands (UHI) Millennium Institute network, and the Southampton Oceanography Centre. Scientists carried out a series of studies, including the use of satellites to assess wave heights in the seas around the west coast and the Hebrides.\\r\\n', 'Pavey focuses on indoor success\\r\\n\\r\\nJo Pavey will miss January\\'s View From Great Edinburgh International Cross Country to focus on preparing for the European Indoor Championships in March.\\r\\n\\r\\nThe 31-year-old was third behind Hayley Yelling and Justyna Bak in last week\\'s European Cross Country Championships but she prefers to race on the track. \"It was great winning bronze but I\\'m wary of injuries and must concentrate on the indoor season,\" she said. \"Because of previous injuries I don\\'t even run up hills in training.\" Pavey, who came fifth in the 5,000m at the Athens Olympics, helped the British cross country team win the team silver medal in Heringsdorf last week. She is likely to start her 3,000m season with a race in either Boston or Stuttgart at the end of January.\\r\\n', 'Tories reject rethink on axed MP\\r\\n\\r\\nSacked MP Howard Flight\\'s local Conservative association has insisted he will not be its candidate at the general election.\\r\\n\\r\\nRussell Tanguay, agent for Arundel and South Downs Tories, said Mr Flight was ineligible to be a candidate and the association was seeking a substitute. The news comes despite Mr Flight\\'s allies saying they had enough support to hold a meeting to discuss his fate. Mr Flight landed in trouble over remarks on Tory tax and spending plans. He quit as Tory deputy chairman after apparently suggesting the Tories planned extra spending cuts - but he wants to continue as an MP.\\r\\n\\r\\nTory headquarters says he cannot stand as a Conservative candidate because he is no longer an approved candidate. Mr Tanguay backed that view on Tuesday, saying: \"Howard Flight is ineligible to stand as a Conservative Party candidate. \"The association is in the process of selecting a new candidate.\"\\r\\n\\r\\nBut the local Tory chairman made similar comments on Friday and dissent continues. Two local councillors who back Mr Flight met Mr Tanguay and the local association\\'s chairman in Arundel on Tuesday afternoon but did not comment as they left the meeting. Mr Flight says he will not stand down as a candidate unless his local party instructs him to do so at an extraordinary general meeting (EGM). The MP, who is consulting his lawyers, told BBC News: \"They selected me and they, if you like, dispose of me or keep me.\" Mr Flight\\'s supporters also say they have the 50 signatures needed to trigger the EGM.\\r\\n\\r\\nAt a news conference, Mr Howard insisted he had played by the party\\'s rules. The Tory leader, who argues he is ensuring honesty, said: \"We do not say one thing in private and another thing in public.\"\\r\\n\\r\\nLabour election campaign coordinator Alan Milburn said the Tories were in \"turmoil\" because Mr Flight had exposed their hidden plans. The comments were not a \"one-off\", he said, claiming Mr Howard and other senior Tories were obsessively committed to cutting public spending. Liberal Democrat chairman Matthew Taylor said: \"Whilst I disagree with Howard Flight\\'s views, it seems extraordinary to sack somebody for telling the truth.\"\\r\\n\\r\\nIt has also emerged Mr Howard has suspended Slough\\'s constituency Conservative association for refusing to deselect its candidate. Adrian Hilton was abandoned after suggesting the signing of the Maastricht Treaty, under John Major\\'s government, was an act of treason. The Catholic Herald also highlighted articles he wrote about the role of Catholicism in the European Union. Mr Hilton was chosen to fight the seat after the previous candidate, Robert Oulds, was sacked for being pictured with a range of guns and a hunting knife. Slough Conservative Association has now been placed on \"support status\" and is being run from Conservative campaign headquarters, says a senior party spokesman.\\r\\n\\r\\nMr Hilton on Tuesday said he was considering taking legal action against his deposal. He said the local party had only learned of the final decision on the BBC News website on Monday evening. \"There are people at Central Office who are behaving like little dictators and seemingly people who are ordinary members are being treated with contempt,\" he said. The party says it did try to contact the local Conservative chairman.\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "dataset = skl.datasets.load_files('data/BBC', encoding=\"latin1\")\n",
    "\n",
    "print(dataset.keys())\n",
    "print(dataset.target_names)\n",
    "print(dataset.target[0:5])\n",
    "print(dataset.filenames[0:5])\n",
    "print(dataset.data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000m</th>\n",
       "      <th>000s</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>001and</th>\n",
       "      <th>001st</th>\n",
       "      <th>...</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zornotza</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 29421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0001  000bn  000m  000s  000th  001  001and  001st  ...  zooms  \\\n",
       "0      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "1      0    2     0      0     0     0      0    0       0      0  ...      0   \n",
       "2      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "3      0    0     0      0     2     0      0    0       0      0  ...      0   \n",
       "4      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "...   ..  ...   ...    ...   ...   ...    ...  ...     ...    ...  ...    ...   \n",
       "2220   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2221   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2222   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2223   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2224   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "\n",
       "      zooropa  zornotza  zorro  zubair  zuluaga  zurich  zutons  zvonareva  \\\n",
       "0           0         0      0       0        0       0       0          0   \n",
       "1           0         0      0       0        0       0       0          0   \n",
       "2           0         0      0       0        0       0       0          0   \n",
       "3           0         0      0       0        0       0       0          0   \n",
       "4           0         0      0       0        0       0       0          0   \n",
       "...       ...       ...    ...     ...      ...     ...     ...        ...   \n",
       "2220        0         0      0       0        0       0       0          0   \n",
       "2221        0         0      0       0        0       0       0          0   \n",
       "2222        0         0      0       0        0       0       0          0   \n",
       "2223        0         0      0       0        0       0       0          0   \n",
       "2224        0         0      0       0        0       0       0          0   \n",
       "\n",
       "      zvyagintsev  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "2220            0  \n",
       "2221            0  \n",
       "2222            0  \n",
       "2223            0  \n",
       "2224            0  \n",
       "\n",
       "[2225 rows x 29421 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "x_word_counts = vec.fit_transform(dataset.data)\n",
    "#print(x_word_counts)\n",
    "#print(vec.get_feature_names_out())\n",
    "\n",
    "pd.DataFrame(data=x_word_counts.toarray(),columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Split Training / Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12684)\t1\n",
      "  (0, 18726)\t9\n",
      "  (0, 26462)\t26\n",
      "  (0, 4980)\t1\n",
      "  (0, 28521)\t4\n",
      "  (0, 26718)\t1\n",
      "  (0, 27901)\t1\n",
      "  (0, 11102)\t16\n",
      "  (0, 18837)\t1\n",
      "  (0, 26730)\t23\n",
      "  (0, 12452)\t2\n",
      "  (0, 17855)\t5\n",
      "  (0, 14557)\t4\n",
      "  (0, 12726)\t1\n",
      "  (0, 26531)\t5\n",
      "  (0, 2429)\t10\n",
      "  (0, 14571)\t1\n",
      "  (0, 23041)\t7\n",
      "  (0, 26792)\t2\n",
      "  (0, 2994)\t4\n",
      "  (0, 13801)\t6\n",
      "  (0, 13073)\t2\n",
      "  (0, 2395)\t1\n",
      "  (0, 467)\t1\n",
      "  (0, 17372)\t1\n",
      "  :\t:\n",
      "  (1779, 18059)\t1\n",
      "  (1779, 4831)\t2\n",
      "  (1779, 2111)\t2\n",
      "  (1779, 4830)\t2\n",
      "  (1779, 5337)\t1\n",
      "  (1779, 3369)\t2\n",
      "  (1779, 16391)\t3\n",
      "  (1779, 19723)\t1\n",
      "  (1779, 2112)\t3\n",
      "  (1779, 16392)\t1\n",
      "  (1779, 2316)\t2\n",
      "  (1779, 1403)\t1\n",
      "  (1779, 4883)\t1\n",
      "  (1779, 28301)\t1\n",
      "  (1779, 6512)\t1\n",
      "  (1779, 3370)\t1\n",
      "  (1779, 10515)\t1\n",
      "  (1779, 18897)\t1\n",
      "  (1779, 10162)\t1\n",
      "  (1779, 5732)\t1\n",
      "  (1779, 10313)\t1\n",
      "  (1779, 17563)\t1\n",
      "  (1779, 4393)\t1\n",
      "  (1779, 7597)\t1\n",
      "  (1779, 25374)\t1\n",
      "[4 4 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = skl.model_selection.train_test_split(x_word_counts, dataset.target, train_size=0.8, random_state=None)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nb = skl.naive_bayes.MultinomialNB()\n",
    "#Train the model using the training sets\n",
    "nb.fit(x_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. Performance Metrics\n",
    " - [x] a clear separator (a sequence of hyphens or stars) and string clearly describing the model (e.g. “Multi- nomialNB default values, try 1”)\n",
    " - [x] the confusion matrix (you can use confusion matrix)\n",
    " - [x] the precision, recall, and F1-measure for each class (you can use classification report)\n",
    " - [x] the accuracy, macro-average F1 and weighted-average F1 of the model (you can use accuracy score and f1 score)\n",
    " - [x] the prior probability of each class\n",
    " - [x] the size of the vocabulary (i.e. the number of different words1)\n",
    " - [x] the number of word-tokens in each class (i.e. the number of words in total2)\n",
    " - [x] the number of word-tokens in the entire corpus\n",
    " - [x] the number and percentage of words with a frequency of zero in each class\n",
    " - [x] the number and percentage of words with a frequency of one in the entire corpus\n",
    " - [x] your 2 favorite words (that are present in the vocabulary) and their log-prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#counts_train = [np.count_nonzero(y_train == k) for k, v in enumerate(dataset.target_names)]\n",
    "priors = { cat: np.count_nonzero(y_train == i)/len(y_train) for i, cat in enumerate(dataset.target_names) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists('output/bbc-performance.txt'):\n",
    "    os.remove('output/bbc-performance.txt')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.FileHandler('output/bbc-performance.txt', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===================\n",
      " Naive Bayes Try 1\n",
      "===================\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[101   0   4   0   3]\n",
      " [  0  78   1   0   1]\n",
      " [  0   0  78   0   0]\n",
      " [  0   0   0 106   0]\n",
      " [  0   0   0   0  73]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      0.94      0.97       108\n",
      "entertainment       1.00      0.97      0.99        80\n",
      "     politics       0.94      1.00      0.97        78\n",
      "        sport       1.00      1.00      1.00       106\n",
      "         tech       0.95      1.00      0.97        73\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "\n",
      "(e) prior probability of each class: \n",
      "{'business': 0.2258426966292135, 'entertainment': 0.17191011235955056, 'politics': 0.1904494382022472, 'sport': 0.22752808988764045, 'tech': 0.1842696629213483}\n",
      "\n",
      "(f) vocabulary size: 29421\n",
      "\n",
      "(g) word-tokens in each class: \n",
      "\n",
      "(h) word-tokens in the entire corpus: \n",
      "\n",
      "(i) the number and percentage of words with a frequency of zero in each class: \n",
      "\n",
      "(j) the number and percentage of words with a frequency of one in the entire corpus: \n",
      "\n",
      "(k) your 2 favorite words (that are present in the vocabulary) and their log-prob: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_dicts[0] ( business) word token count -->  34624\n",
      "\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "word_freq_dicts[1] ( entertainment) word token count -->  25613\n",
      "\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "word_freq_dicts[2] ( politics) word token count -->  35046\n",
      "\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "word_freq_dicts[3] ( sport) word token count -->  33121\n",
      "\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "word_freq_dicts[4] ( tech) word token count -->  35299\n",
      "\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "running_sum of word tokens in entire corpus 836357\n",
      "current_category business\n",
      "total 0 frequency words: 24223\n",
      "corresponding percentage: 82.33234764284015%\n",
      "current_category entertainment\n",
      "total 0 frequency words: 24436\n",
      "corresponding percentage: 83.05632031542096%\n",
      "current_category politics\n",
      "total 0 frequency words: 24345\n",
      "corresponding percentage: 82.74701743652493%\n",
      "current_category sport\n",
      "total 0 frequency words: 24449\n",
      "corresponding percentage: 83.10050644097753%\n",
      "current_category tech\n",
      "total 0 frequency words: 24246\n",
      "corresponding percentage: 82.41052309574793%\n",
      "total one frequency words: 24932\n",
      "percentage of one frequency words: 2.981023653774644%\n",
      "\n",
      "\n",
      "FAVORITE WORDS: the and abdullah\n",
      "case: the\n",
      "log_prob_hefty: 3.2340854121957364e-05\n",
      "case: abdullah\n",
      "log_prob_abdullah: 2.31006100871124e-06\n"
     ]
    }
   ],
   "source": [
    "nb_runs = 1 # try counter\n",
    "\n",
    "def performance_report(test, pred):\n",
    "    print = logger.info\n",
    "    \n",
    "    global nb_runs\n",
    "    print('===================')\n",
    "    print(' Naive Bayes Try ' + str(nb_runs))\n",
    "    print('===================')\n",
    "    nb_runs+=1\n",
    "\n",
    "    print('\\n(b) confusion_matrix:')\n",
    "    print(skl.metrics.confusion_matrix(test, pred))\n",
    "    print(\"\\n(c/d) classification_report: \")\n",
    "    print(skl.metrics.classification_report(test, pred, target_names=dataset.target_names))\n",
    "\n",
    "    #print(\"\\n(d) accuracy_score: \")\n",
    "    #print(metrics.accuracy_score(test, pred))\n",
    "    #print(\"\\n(d) f1_score (macro avg): \")\n",
    "    #print(metrics.f1_score(test, pred, average='macro'))\n",
    "    #print(\"\\n(d) f1_score (weighted avg): \")\n",
    "    #print(metrics.f1_score(test, pred, average='weighted'))\n",
    "\n",
    "    print(\"\\n(e) prior probability of each class: \")\n",
    "    print(priors)\n",
    "    print(\"\\n(f) vocabulary size: \" + str(len(vec.get_feature_names_out())))\n",
    "    #LEFT TODO:\n",
    "    print(\"\\n(g) word-tokens in each class: \")\n",
    "    print(\"\\n(h) word-tokens in the entire corpus: \")# + np.add.reduce(x_word_counts.toarray()))\n",
    "    print(\"\\n(i) the number and percentage of words with a frequency of zero in each class: \")\n",
    "    print(\"\\n(j) the number and percentage of words with a frequency of one in the entire corpus: \")\n",
    "    print(\"\\n(k) your 2 favorite words (that are present in the vocabulary) and their log-prob: \")\n",
    "    # something with nb.feature_log_prob_ ? find word index, look up log-prob in feature_log_prob_, not sure what to do about the 5 diff rows\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "performance_report(y_test, y_pred)\n",
    "\n",
    "inverted_vocab = dict(zip(vec.vocabulary_.values(), vec.vocabulary_.keys()))\n",
    "\n",
    "# word frequency for test data\n",
    "word_freq_dicts = [{}, {}, {}, {}, {}] # per category\n",
    "word_freq_sums = [0, 0, 0, 0, 0]\n",
    "ctr = 0\n",
    "\n",
    "for x in x_test:\n",
    "    category = y_test[ctr]\n",
    "    current_dict = word_freq_dicts[category]\n",
    "    current_sum = word_freq_sums[category]\n",
    "    x_test_snippet = dict(zip(x[0].indices, x[0].data))\n",
    "\n",
    "    for i in x_test_snippet:\n",
    "        occurance = x_test_snippet[i]\n",
    "        word = inverted_vocab[i]\n",
    "        current_dict[word] = occurance\n",
    "        current_sum += occurance\n",
    "        word_freq_sums[category] = current_sum\n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "for i in range(len(word_freq_dicts)):\n",
    "    #print('word_freq_dicts[' + str(i) + '] ( ' + dataset.target_names[i] + ')', word_freq_dicts[i])\n",
    "    print('word_freq_dicts[' + str(i) + '] ( ' + dataset.target_names[i] + ') word token count --> ', word_freq_sums[i])\n",
    "    print('\\n\\n-------------------------------------------------\\n\\n')\n",
    "\n",
    "# word frequency for test + training data\n",
    "\n",
    "word_freq_map_all = {}\n",
    "x_merged_sets = sp.vstack((x_test, x_train))\n",
    "\n",
    "total_corpus_sum = 0\n",
    "\n",
    "for x in x_merged_sets:\n",
    "    x_test_snippet = dict(zip(x[0].indices, x[0].data))\n",
    "    for i in x_test_snippet:\n",
    "        occurance = x_test_snippet[i]\n",
    "        word = inverted_vocab[i]\n",
    "        word_freq_map_all[word] = occurance\n",
    "        total_corpus_sum += occurance\n",
    "\n",
    "print('running_sum of word tokens in entire corpus', total_corpus_sum)\n",
    "\n",
    "# frequency of zero per category\n",
    "i = 0\n",
    "total_vocab_words = len(vec.vocabulary_.keys())\n",
    "\n",
    "for current_dict in word_freq_dicts:\n",
    "    current_category = dataset.target_names[i]\n",
    "    print('current_category', current_category)\n",
    "    category_words_set = set(current_dict.keys())\n",
    "    vocab_words_set = set(vec.vocabulary_.keys())\n",
    "    set_diff_result = vocab_words_set.difference(category_words_set)\n",
    "    total_zero_freq_words = len(set_diff_result)\n",
    "    print('total 0 frequency words:', total_zero_freq_words)\n",
    "    print('corresponding percentage: ' + str(100 * (total_zero_freq_words/total_vocab_words)) + '%')\n",
    "    i += 1\n",
    "\n",
    "# frequency of one for entire corpus\n",
    "\n",
    "freq_one_sum = 0\n",
    "for entry in word_freq_map_all:\n",
    "    if word_freq_map_all[entry] == 1:\n",
    "        freq_one_sum += 1\n",
    "\n",
    "print('total one frequency words: ' + str(freq_one_sum))\n",
    "print('percentage of one frequency words: ' + str(100 * freq_one_sum/total_corpus_sum) + '%')\n",
    "#print('word_freq_map_all', word_freq_map_all)\n",
    "\n",
    "# 2 fav words: the, abdullah\n",
    "# compute log frequency\n",
    "# formula: (N_yi + alpha)/(N_y + alpha * n)\n",
    "# where\n",
    "# N_yi --> # occurance of \"favorite\" word\n",
    "# N_y --> total amount of words\n",
    "# alpha --> 1, default value as per sklearn\n",
    "# n --> size of vocabulary\n",
    "print('\\n\\nFAVORITE WORDS: the and abdullah')\n",
    "print('case: the')\n",
    "N_yi = word_freq_map_all['the']\n",
    "N_y = total_corpus_sum\n",
    "alpha = 1\n",
    "n = len(word_freq_map_all)\n",
    "log_prob_hefty = (N_yi + alpha)/(N_y + alpha * n)\n",
    "print('log_prob_hefty: ' + str(log_prob_hefty))\n",
    "\n",
    "print('case: abdullah')\n",
    "N_yi = word_freq_map_all['abdullah']\n",
    "log_prob_abdullah = (N_yi + alpha)/(N_y + alpha * n)\n",
    "print('log_prob_abdullah: ' + str(log_prob_abdullah))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "8. Naive Bayes, Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===================\n",
      " Naive Bayes Try 2\n",
      "===================\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[101   0   4   0   3]\n",
      " [  0  78   1   0   1]\n",
      " [  0   0  78   0   0]\n",
      " [  0   0   0 106   0]\n",
      " [  0   0   0   0  73]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      0.94      0.97       108\n",
      "entertainment       1.00      0.97      0.99        80\n",
      "     politics       0.94      1.00      0.97        78\n",
      "        sport       1.00      1.00      1.00       106\n",
      "         tech       0.95      1.00      0.97        73\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "\n",
      "(e) prior probability of each class: \n",
      "{'business': 0.2258426966292135, 'entertainment': 0.17191011235955056, 'politics': 0.1904494382022472, 'sport': 0.22752808988764045, 'tech': 0.1842696629213483}\n",
      "\n",
      "(f) vocabulary size: 29421\n",
      "\n",
      "(g) word-tokens in each class: \n",
      "\n",
      "(h) word-tokens in the entire corpus: \n",
      "\n",
      "(i) the number and percentage of words with a frequency of zero in each class: \n",
      "\n",
      "(j) the number and percentage of words with a frequency of one in the entire corpus: \n",
      "\n",
      "(k) your 2 favorite words (that are present in the vocabulary) and their log-prob: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb2 = skl.naive_bayes.MultinomialNB()\n",
    "nb2.fit(x_train, y_train)\n",
    "\n",
    "performance_report(y_test, nb2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Naive Bayes, Try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===================\n",
      " Naive Bayes Try 3\n",
      "===================\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[103   0   2   0   3]\n",
      " [  0  80   0   0   0]\n",
      " [  1   0  77   0   0]\n",
      " [  0   0   1 105   0]\n",
      " [  0   0   0   0  73]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.99      0.95      0.97       108\n",
      "entertainment       1.00      1.00      1.00        80\n",
      "     politics       0.96      0.99      0.97        78\n",
      "        sport       1.00      0.99      1.00       106\n",
      "         tech       0.96      1.00      0.98        73\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.99      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "\n",
      "(e) prior probability of each class: \n",
      "{'business': 0.2258426966292135, 'entertainment': 0.17191011235955056, 'politics': 0.1904494382022472, 'sport': 0.22752808988764045, 'tech': 0.1842696629213483}\n",
      "\n",
      "(f) vocabulary size: 29421\n",
      "\n",
      "(g) word-tokens in each class: \n",
      "\n",
      "(h) word-tokens in the entire corpus: \n",
      "\n",
      "(i) the number and percentage of words with a frequency of zero in each class: \n",
      "\n",
      "(j) the number and percentage of words with a frequency of one in the entire corpus: \n",
      "\n",
      "(k) your 2 favorite words (that are present in the vocabulary) and their log-prob: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb3 = skl.naive_bayes.MultinomialNB(alpha=0.0001)\n",
    "nb3.fit(x_train, y_train)\n",
    "\n",
    "performance_report(y_test, nb3.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Naive Bayes, Try 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===================\n",
      " Naive Bayes Try 4\n",
      "===================\n",
      "\n",
      "(b) confusion_matrix:\n",
      "[[101   0   4   0   3]\n",
      " [  0  79   0   0   1]\n",
      " [  0   0  78   0   0]\n",
      " [  0   0   0 106   0]\n",
      " [  0   0   0   0  73]]\n",
      "\n",
      "(c/d) classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      0.94      0.97       108\n",
      "entertainment       1.00      0.99      0.99        80\n",
      "     politics       0.95      1.00      0.97        78\n",
      "        sport       1.00      1.00      1.00       106\n",
      "         tech       0.95      1.00      0.97        73\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "\n",
      "(e) prior probability of each class: \n",
      "{'business': 0.2258426966292135, 'entertainment': 0.17191011235955056, 'politics': 0.1904494382022472, 'sport': 0.22752808988764045, 'tech': 0.1842696629213483}\n",
      "\n",
      "(f) vocabulary size: 29421\n",
      "\n",
      "(g) word-tokens in each class: \n",
      "\n",
      "(h) word-tokens in the entire corpus: \n",
      "\n",
      "(i) the number and percentage of words with a frequency of zero in each class: \n",
      "\n",
      "(j) the number and percentage of words with a frequency of one in the entire corpus: \n",
      "\n",
      "(k) your 2 favorite words (that are present in the vocabulary) and their log-prob: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb4 = skl.naive_bayes.MultinomialNB(alpha=0.9)\n",
    "nb4.fit(x_train, y_train)\n",
    "\n",
    "performance_report(y_test, nb4.predict(x_test))\n",
    "\n",
    "nb_runs = 1 # reset try count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. TODO: Write BBC-discussions.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOM4FWTEFHATi4Q0tnMefGC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
